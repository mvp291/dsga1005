{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyGPs\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import rbf_kernel, laplacian_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_gp_regression(X_train, y_train, X_test):\n",
    "    model = pyGPs.GPR()\n",
    "    m = pyGPs.mean.Const()\n",
    "    k = pyGPs.cov.RBF()\n",
    "    model.setPrior(mean=m, kernel=k)\n",
    "    model.optimize(X_train, y_train)\n",
    "    print('Optimized negative log marginal likelihood:', round(model.nlZ,3))\n",
    "    y_pred, _, _, _, _ = model.predict(X_test)\n",
    "    return y_pred\n",
    "\n",
    "def HSIC_d(X, Y, kernel='exponential'):\n",
    "    n = len(X)\n",
    "\n",
    "    if kernel == 'exponential':\n",
    "        apply_kernel = rbf_kernel\n",
    "    elif kernel == 'laplacian':\n",
    "        apply_kernel = laplacian_kernel\n",
    "    K = apply_kernel(X.reshape(-1, 1))\n",
    "    L = apply_kernel(Y.reshape(-1, 1))\n",
    "    \n",
    "    H = np.eye(n) - np.ones((n, n)) * (1.0 / n)\n",
    "    return ((n - 1) ** -2) * np.trace(np.dot(np.dot(np.dot(K, H), L), H))\n",
    "\n",
    "\n",
    "def ANM_algorithm(X,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "    leakage_prob = dict()\n",
    "    \n",
    "    for col in range(X_train.shape[1]):\n",
    "        \n",
    "        x_train_column = X_train[:,col]\n",
    "        x_test_column = X_test[:,col]\n",
    "        \n",
    "        print x_train_column.shape, y_train.shape, x_test_column.shape\n",
    "        \n",
    "        y_pred = compute_gp_regression(x_train_column, y_train, x_test_column)\n",
    "        x_pred = compute_gp_regression(y_train, x_train_column, y_test)\n",
    "        print 'y_pred shape', y_pred.shape\n",
    "        print 'x_pred shape', x_pred.shape\n",
    "        \n",
    "        y_residuals = y_test - y_pred.ravel() # esto no deberia ser absolute value?\n",
    "        x_residuals = x_test_column - x_pred.ravel()\n",
    "        \n",
    "        print y_residuals.shape\n",
    "        print x_test_column.shape\n",
    "        \n",
    "        print x_residuals.shape\n",
    "        print y_test.shape\n",
    "        \n",
    "        \n",
    "        HSIC_x_to_y = HSIC_d(x_test_column, y_residuals)\n",
    "        HSIC_y_to_x = HSIC_d(y_test, x_residuals)\n",
    "        \n",
    "        \n",
    "        diff_HSIC = HSIC_x_to_y - HSIC_y_to_x\n",
    "    \n",
    "        \n",
    "        leakage_prob[diff_HSIC] = col\n",
    "    \n",
    "    keys = leakage_prob.keys()\n",
    "    keys.sort(reverse=True)\n",
    "    for key in keys:\n",
    "        print \"The probability of column: \" + str(leakage_prob[key]) + \" is: \" + str(key)\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pairs = pd.read_csv('data/pair0039.txt', sep=' ', header=None)\n",
    "pairs.columns = ['X', 'Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.array(pairs)[:,0].reshape(-1,1)\n",
    "y = np.array(pairs)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of line searches 40\n",
      "('Optimized negative log marginal likelihood:', 2435.659)\n",
      "Number of line searches 40\n",
      "('Optimized negative log marginal likelihood:', 2435.659)\n",
      "y_pred shape (131, 1)\n",
      "x_pred shape (131, 1)\n",
      "(131,)\n",
      "(131,)\n",
      "(131,)\n",
      "(131,)\n",
      "(131,)\n",
      "The probability of column: 0 is: -0.00114255125667\n"
     ]
    }
   ],
   "source": [
    "ANM_algorithm(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
       "       'TAX', 'PTRATIO', 'B', 'LSTAT'], \n",
       "      dtype='|S7')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Boston House Prices dataset\\n===========================\\n\\nNotes\\n------\\nData Set Characteristics:  \\n\\n    :Number of Instances: 506 \\n\\n    :Number of Attributes: 13 numeric/categorical predictive\\n    \\n    :Median Value (attribute 14) is usually the target\\n\\n    :Attribute Information (in order):\\n        - CRIM     per capita crime rate by town\\n        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\\n        - INDUS    proportion of non-retail business acres per town\\n        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\\n        - NOX      nitric oxides concentration (parts per 10 million)\\n        - RM       average number of rooms per dwelling\\n        - AGE      proportion of owner-occupied units built prior to 1940\\n        - DIS      weighted distances to five Boston employment centres\\n        - RAD      index of accessibility to radial highways\\n        - TAX      full-value property-tax rate per $10,000\\n        - PTRATIO  pupil-teacher ratio by town\\n        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\\n        - LSTAT    % lower status of the population\\n        - MEDV     Median value of owner-occupied homes in $1000's\\n\\n    :Missing Attribute Values: None\\n\\n    :Creator: Harrison, D. and Rubinfeld, D.L.\\n\\nThis is a copy of UCI ML housing dataset.\\nhttp://archive.ics.uci.edu/ml/datasets/Housing\\n\\n\\nThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\\n\\nThe Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\\nprices and the demand for clean air', J. Environ. Economics & Management,\\nvol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\\n...', Wiley, 1980.   N.B. Various transformations are used in the table on\\npages 244-261 of the latter.\\n\\nThe Boston house-price data has been used in many machine learning papers that address regression\\nproblems.   \\n     \\n**References**\\n\\n   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\\n   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\\n   - many more! (see http://archive.ics.uci.edu/ml/datasets/Housing)\\n\""
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.DESCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = boston.data\n",
    "y = boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506,)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(339,) (339,) (167,)\n",
      "Number of line searches 40\n",
      "('Optimized negative log marginal likelihood:', 1208.048)\n",
      "Number of line searches 40\n",
      "('Optimized negative log marginal likelihood:', 1111.66)\n",
      "y_pred shape (167, 1)\n",
      "x_pred shape (167, 1)\n",
      "(167,)\n",
      "(167,)\n",
      "(167,)\n",
      "(167,)\n",
      "(339,) (339,) (167,)\n",
      "Number of line searches 40\n",
      "('Optimized negative log marginal likelihood:', 1227.439)\n",
      "Number of line searches 40\n",
      "('Optimized negative log marginal likelihood:', 1510.418)\n",
      "y_pred shape (167, 1)\n",
      "x_pred shape (167, 1)\n",
      "(167,)\n",
      "(167,)\n",
      "(167,)\n",
      "(167,)\n",
      "(339,) (339,) (167,)\n",
      "Number of line searches 40\n",
      "('Optimized negative log marginal likelihood:', 1189.604)\n",
      "Number of line searches 40\n",
      "('Optimized negative log marginal likelihood:', 1067.432)\n",
      "y_pred shape (167, 1)\n",
      "x_pred shape (167, 1)\n",
      "(167,)\n",
      "(167,)\n",
      "(167,)\n",
      "(167,)\n",
      "(339,) (339,) (167,)\n",
      "Number of line searches 40\n",
      "('Optimized negative log marginal likelihood:', 1236.236)\n",
      "Number of line searches 40\n",
      "('Optimized negative log marginal likelihood:', 25.543)\n",
      "y_pred shape (167, 1)\n",
      "x_pred shape (167, 1)\n",
      "(167,)\n",
      "(167,)\n",
      "(167,)\n",
      "(167,)\n",
      "(339,) (339,) (167,)\n",
      "Number of line searches 40\n",
      "('Optimized negative log marginal likelihood:', 1212.917)\n",
      "Number of line searches 40\n",
      "('Optimized negative log marginal likelihood:', -309.415)\n",
      "y_pred shape (167, 1)\n",
      "x_pred shape (167, 1)\n",
      "(167,)\n",
      "(167,)\n",
      "(167,)\n",
      "(167,)\n",
      "(339,) (339,) (167,)\n",
      "Number of line searches 40\n",
      "('Optimized negative log marginal likelihood:', 1107.227)\n",
      "Number of line searches 34\n",
      "('Optimized negative log marginal likelihood:', 253.242)\n",
      "y_pred shape (167, 1)\n",
      "x_pred shape (167, 1)\n",
      "(167,)\n",
      "(167,)\n",
      "(167,)\n",
      "(167,)\n",
      "(339,) (339,) (167,)\n",
      "Number of line searches 40\n",
      "('Optimized negative log marginal likelihood:', 1222.879)\n",
      "Number of line searches 40\n",
      "('Optimized negative log marginal likelihood:', 1557.402)\n",
      "y_pred shape (167, 1)\n",
      "x_pred shape (167, 1)\n",
      "(167,)\n",
      "(167,)\n",
      "(167,)\n",
      "(167,)\n",
      "(339,) (339,) (167,)\n",
      "Number of line searches 40\n",
      "('Optimized negative log marginal likelihood:', 1231.582)\n",
      "Number of line searches 40\n",
      "('Optimized negative log marginal likelihood:', 702.502)\n",
      "y_pred shape (167, 1)\n",
      "x_pred shape (167, 1)\n",
      "(167,)\n",
      "(167,)\n",
      "(167,)\n",
      "(167,)\n",
      "(339,) (339,) (167,)\n",
      "Number of line searches 40\n",
      "('Optimized negative log marginal likelihood:', 1207.465)\n",
      "Number of line searches 40\n",
      "('Optimized negative log marginal likelihood:', 1155.245)\n",
      "y_pred shape (167, 1)\n",
      "x_pred shape (167, 1)\n",
      "(167,)\n",
      "(167,)\n",
      "(167,)\n",
      "(167,)\n",
      "(339,) (339,) (167,)\n",
      "Number of line searches 40\n",
      "('Optimized negative log marginal likelihood:', 1209.047)\n",
      "Number of line searches 40\n",
      "('Optimized negative log marginal likelihood:', 2141.443)\n",
      "y_pred shape (167, 1)\n",
      "x_pred shape (167, 1)\n",
      "(167,)\n",
      "(167,)\n",
      "(167,)\n",
      "(167,)\n",
      "(339,) (339,) (167,)\n",
      "Warning: adding jitter of 9.7612971734e+05 to diagnol of kernel matrix for numerical stability\n",
      "Warning: adding jitter of 9.7612971734e+06 to diagnol of kernel matrix for numerical stability\n",
      "Warning: adding jitter of 9.7612971734e+07 to diagnol of kernel matrix for numerical stability\n",
      "Warning: adding jitter of 9.7612971734e+08 to diagnol of kernel matrix for numerical stability\n",
      "Warning: adding jitter of 9.7612971734e+09 to diagnol of kernel matrix for numerical stability\n",
      "Number of line searches 40\n",
      "('Optimized negative log marginal likelihood:', 1194.508)\n",
      "Number of line searches 40\n",
      "('Optimized negative log marginal likelihood:', 707.207)\n",
      "y_pred shape (167, 1)\n",
      "x_pred shape (167, 1)\n",
      "(167,)\n",
      "(167,)\n",
      "(167,)\n",
      "(167,)\n",
      "(339,) (339,) (167,)\n",
      "Number of line searches 40\n",
      "('Optimized negative log marginal likelihood:', 1219.053)\n",
      "Warning: adding jitter of 4.7916475229e+12 to diagnol of kernel matrix for numerical stability\n",
      "Warning: adding jitter of 4.7916475229e+13 to diagnol of kernel matrix for numerical stability\n",
      "Warning: adding jitter of 4.7916475229e+14 to diagnol of kernel matrix for numerical stability\n",
      "Warning: adding jitter of 4.7916475229e+15 to diagnol of kernel matrix for numerical stability\n",
      "Warning: adding jitter of 4.7916475229e+16 to diagnol of kernel matrix for numerical stability\n",
      "Number of line searches 40\n",
      "('Optimized negative log marginal likelihood:', 1971.665)\n",
      "y_pred shape (167, 1)\n",
      "x_pred shape (167, 1)\n",
      "(167,)\n",
      "(167,)\n",
      "(167,)\n",
      "(167,)\n",
      "(339,) (339,) (167,)\n",
      "Number of line searches 40\n",
      "('Optimized negative log marginal likelihood:', 1053.072)\n",
      "Number of line searches 40\n",
      "('Optimized negative log marginal likelihood:', 959.063)\n",
      "y_pred shape (167, 1)\n",
      "x_pred shape (167, 1)\n",
      "(167,)\n",
      "(167,)\n",
      "(167,)\n",
      "(167,)\n",
      "The probability of column: 12 is: 0.00149305048352\n",
      "The probability of column: 5 is: 9.52529158381e-05\n",
      "The probability of column: 4 is: -5.05522560742e-06\n",
      "The probability of column: 3 is: -1.16502517361e-05\n",
      "The probability of column: 9 is: -0.000599836560431\n",
      "The probability of column: 6 is: -0.000834835429529\n",
      "The probability of column: 7 is: -0.000926073969679\n",
      "The probability of column: 10 is: -0.00174040422681\n",
      "The probability of column: 11 is: -0.00262653264801\n",
      "The probability of column: 2 is: -0.00430590121497\n",
      "The probability of column: 8 is: -0.00967054417892\n",
      "The probability of column: 0 is: -0.0109522976416\n",
      "The probability of column: 1 is: -0.0289051424721\n"
     ]
    }
   ],
   "source": [
    "ANM_algorithm(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4.98,   9.14,   4.03,   2.94,   5.33,   5.21,  12.43,  19.15,\n",
       "        29.93,  17.1 ,  20.45,  13.27,  15.71,   8.26,  10.26,   8.47,\n",
       "         6.58,  14.67,  11.69,  11.28,  21.02,  13.83,  18.72,  19.88,\n",
       "        16.3 ,  16.51,  14.81,  17.28,  12.8 ,  11.98,  22.6 ,  13.04,\n",
       "        27.71,  18.35,  20.34,   9.68,  11.41,   8.77,  10.13,   4.32,\n",
       "         1.98,   4.84,   5.81,   7.44,   9.55,  10.21,  14.15,  18.8 ,\n",
       "        30.81,  16.2 ,  13.45,   9.43,   5.28,   8.43,  14.8 ,   4.81,\n",
       "         5.77,   3.95,   6.86,   9.22,  13.15,  14.44,   6.73,   9.5 ,\n",
       "         8.05,   4.67,  10.24,   8.1 ,  13.09,   8.79,   6.72,   9.88,\n",
       "         5.52,   7.54,   6.78,   8.94,  11.97,  10.27,  12.34,   9.1 ,\n",
       "         5.29,   7.22,   6.72,   7.51,   9.62,   6.53,  12.86,   8.44,\n",
       "         5.5 ,   5.7 ,   8.81,   8.2 ,   8.16,   6.21,  10.59,   6.65,\n",
       "        11.34,   4.21,   3.57,   6.19,   9.42,   7.67,  10.63,  13.44,\n",
       "        12.33,  16.47,  18.66,  14.09,  12.27,  15.55,  13.  ,  10.16,\n",
       "        16.21,  17.09,  10.45,  15.76,  12.04,  10.3 ,  15.37,  13.61,\n",
       "        14.37,  14.27,  17.93,  25.41,  17.58,  14.81,  27.26,  17.19,\n",
       "        15.39,  18.34,  12.6 ,  12.26,  11.12,  15.03,  17.31,  16.96,\n",
       "        16.9 ,  14.59,  21.32,  18.46,  24.16,  34.41,  26.82,  26.42,\n",
       "        29.29,  27.8 ,  16.65,  29.53,  28.32,  21.45,  14.1 ,  13.28,\n",
       "        12.12,  15.79,  15.12,  15.02,  16.14,   4.59,   6.43,   7.39,\n",
       "         5.5 ,   1.73,   1.92,   3.32,  11.64,   9.81,   3.7 ,  12.14,\n",
       "        11.1 ,  11.32,  14.43,  12.03,  14.69,   9.04,   9.64,   5.33,\n",
       "        10.11,   6.29,   6.92,   5.04,   7.56,   9.45,   4.82,   5.68,\n",
       "        13.98,  13.15,   4.45,   6.68,   4.56,   5.39,   5.1 ,   4.69,\n",
       "         2.87,   5.03,   4.38,   2.97,   4.08,   8.61,   6.62,   4.56,\n",
       "         4.45,   7.43,   3.11,   3.81,   2.88,  10.87,  10.97,  18.06,\n",
       "        14.66,  23.09,  17.27,  23.98,  16.03,   9.38,  29.55,   9.47,\n",
       "        13.51,   9.69,  17.92,  10.5 ,   9.71,  21.46,   9.93,   7.6 ,\n",
       "         4.14,   4.63,   3.13,   6.36,   3.92,   3.76,  11.65,   5.25,\n",
       "         2.47,   3.95,   8.05,  10.88,   9.54,   4.73,   6.36,   7.37,\n",
       "        11.38,  12.4 ,  11.22,   5.19,  12.5 ,  18.46,   9.16,  10.15,\n",
       "         9.52,   6.56,   5.9 ,   3.59,   3.53,   3.54,   6.57,   9.25,\n",
       "         3.11,   5.12,   7.79,   6.9 ,   9.59,   7.26,   5.91,  11.25,\n",
       "         8.1 ,  10.45,  14.79,   7.44,   3.16,  13.65,  13.  ,   6.59,\n",
       "         7.73,   6.58,   3.53,   2.98,   6.05,   4.16,   7.19,   4.85,\n",
       "         3.76,   4.59,   3.01,   3.16,   7.85,   8.23,  12.93,   7.14,\n",
       "         7.6 ,   9.51,   3.33,   3.56,   4.7 ,   8.58,  10.4 ,   6.27,\n",
       "         7.39,  15.84,   4.97,   4.74,   6.07,   9.5 ,   8.67,   4.86,\n",
       "         6.93,   8.93,   6.47,   7.53,   4.54,   9.97,  12.64,   5.98,\n",
       "        11.72,   7.9 ,   9.28,  11.5 ,  18.33,  15.94,  10.36,  12.73,\n",
       "         7.2 ,   6.87,   7.7 ,  11.74,   6.12,   5.08,   6.15,  12.79,\n",
       "         9.97,   7.34,   9.09,  12.43,   7.83,   5.68,   6.75,   8.01,\n",
       "         9.8 ,  10.56,   8.51,   9.74,   9.29,   5.49,   8.65,   7.18,\n",
       "         4.61,  10.53,  12.67,   6.36,   5.99,   5.89,   5.98,   5.49,\n",
       "         7.79,   4.5 ,   8.05,   5.57,  17.6 ,  13.27,  11.48,  12.67,\n",
       "         7.79,  14.19,  10.19,  14.64,   5.29,   7.12,  14.  ,  13.33,\n",
       "         3.26,   3.73,   2.96,   9.53,   8.88,  34.77,  37.97,  13.44,\n",
       "        23.24,  21.24,  23.69,  21.78,  17.21,  21.08,  23.6 ,  24.56,\n",
       "        30.63,  30.81,  28.28,  31.99,  30.62,  20.85,  17.11,  18.76,\n",
       "        25.68,  15.17,  16.35,  17.12,  19.37,  19.92,  30.59,  29.97,\n",
       "        26.77,  20.32,  20.31,  19.77,  27.38,  22.98,  23.34,  12.13,\n",
       "        26.4 ,  19.78,  10.11,  21.22,  34.37,  20.08,  36.98,  29.05,\n",
       "        25.79,  26.64,  20.62,  22.74,  15.02,  15.7 ,  14.1 ,  23.29,\n",
       "        17.16,  24.39,  15.69,  14.52,  21.52,  24.08,  17.64,  19.69,\n",
       "        12.03,  16.22,  15.17,  23.27,  18.05,  26.45,  34.02,  22.88,\n",
       "        22.11,  19.52,  16.59,  18.85,  23.79,  23.98,  17.79,  16.44,\n",
       "        18.13,  19.31,  17.44,  17.73,  17.27,  16.74,  18.71,  18.13,\n",
       "        19.01,  16.94,  16.23,  14.7 ,  16.42,  14.65,  13.99,  10.29,\n",
       "        13.22,  14.13,  17.15,  21.32,  18.13,  14.76,  16.29,  12.87,\n",
       "        14.36,  11.66,  18.14,  24.1 ,  18.68,  24.91,  18.03,  13.11,\n",
       "        10.74,   7.74,   7.01,  10.42,  13.34,  10.58,  14.98,  11.45,\n",
       "        18.06,  23.97,  29.68,  18.07,  13.35,  12.01,  13.59,  17.6 ,\n",
       "        21.14,  14.1 ,  12.92,  15.1 ,  14.33,   9.67,   9.08,   5.64,\n",
       "         6.48,   7.88])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:,12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py2]",
   "language": "python",
   "name": "conda-env-py2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
